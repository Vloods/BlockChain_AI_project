{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513737fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from torch_geometric.nn import GATv2Conv as GATConv, SAGEConv, GCNConv\n",
    "\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "NODE_FEATURE_DIM = 778\n",
    "HIDDEN_DIM = 128\n",
    "EMBEDDING_DIM = 64\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024 * 10\n",
    "NEG_SAMPLE_RATIO = 2.0\n",
    "TRAIN_RATIO = 0.85\n",
    "DATA_DIR = 'data'\n",
    "MODEL_DIR = 'models'\n",
    "\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=[8, 4, 1], dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads[0], dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_channels * heads[0], hidden_channels, heads=heads[1], dropout=dropout)\n",
    "        self.gat3 = GATConv(hidden_channels * heads[1], out_channels, heads=heads[2], dropout=dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.gat2(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.gat3(x, edge_index)\n",
    "\n",
    "\n",
    "class GraphSAGEEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.conv3(x, edge_index)\n",
    "\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return self.conv3(x, edge_index)\n",
    "\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        input_dim = 3 * embedding_dim + 1\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim // 2, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, emb, edge_pairs):\n",
    "        src = emb[edge_pairs[:, 0]]\n",
    "        dst = emb[edge_pairs[:, 1]]\n",
    "        h_cat = torch.cat([src, dst], dim=1)\n",
    "        h_mul = src * dst\n",
    "        h_dot = (src * dst).sum(dim=1, keepdim=True)\n",
    "        x = torch.cat([h_cat, h_mul, h_dot], dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return torch.sigmoid(self.fc3(x)).squeeze()\n",
    "\n",
    "\n",
    "model_classes = {\n",
    "    'GAT': GATEncoder,\n",
    "    'SAGE': GraphSAGEEncoder,\n",
    "    'GCN': GCNEncoder,\n",
    "}\n",
    "\n",
    "\n",
    "dataset_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.pt')]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, EncoderClass in model_classes.items():\n",
    "    for dataset_file in dataset_files:\n",
    "        dataset_path = os.path.join(DATA_DIR, dataset_file)\n",
    "        dataset_name = dataset_file.replace('.pt', '')\n",
    "        pyg_data = torch.load(dataset_path)\n",
    "        NODE_FEATURE_DIM = pyg_data.x.shape[1]\n",
    "        edge_index = pyg_data.edge_index\n",
    "        num_edges = edge_index.size(1)\n",
    "        perm = torch.randperm(num_edges)\n",
    "        train_size = int(num_edges * TRAIN_RATIO)\n",
    "        train_edges = edge_index[:, perm[:train_size]]\n",
    "        test_edges = edge_index[:, perm[train_size:]]\n",
    "        train_data = Data(x=pyg_data.x, edge_index=train_edges)\n",
    "\n",
    "        train_loader = NeighborLoader(\n",
    "            train_data,\n",
    "            num_neighbors=[10, 5],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        encoder = EncoderClass(NODE_FEATURE_DIM, HIDDEN_DIM, EMBEDDING_DIM).to(DEVICE)\n",
    "        predictor = LinkPredictor(EMBEDDING_DIM).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            list(encoder.parameters()) + list(predictor.parameters()),\n",
    "            lr=0.001,\n",
    "            weight_decay=1e-4\n",
    "        )\n",
    "\n",
    "        # Обучение\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            encoder.train()\n",
    "            predictor.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for batch in tqdm(train_loader, desc=f\"{model_name}-{dataset_name} Epoch {epoch}\", leave=False):\n",
    "                batch = batch.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                out = encoder(batch.x.float(), batch.edge_index)\n",
    "                pos_edge_index = batch.edge_index.t()\n",
    "                num_pos = pos_edge_index.size(0)\n",
    "                num_neg = int(num_pos * NEG_SAMPLE_RATIO)\n",
    "\n",
    "                neg_edge_index = negative_sampling(\n",
    "                    edge_index=pos_edge_index.t(),\n",
    "                    num_nodes=batch.num_nodes,\n",
    "                    num_neg_samples=num_neg,\n",
    "                    method='sparse'\n",
    "                ).t()\n",
    "\n",
    "                all_edges = torch.cat([pos_edge_index, neg_edge_index], dim=0)\n",
    "                labels = torch.cat([\n",
    "                    torch.ones(num_pos, device=DEVICE),\n",
    "                    torch.zeros(num_neg, device=DEVICE)\n",
    "                ])\n",
    "                preds = predictor(out, all_edges)\n",
    "                loss = F.binary_cross_entropy(preds, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_pos = test_edges.t().to(DEVICE)\n",
    "            num_test = test_pos.size(0)\n",
    "            test_neg = negative_sampling(\n",
    "                edge_index=test_edges,\n",
    "                num_nodes=pyg_data.num_nodes,\n",
    "                num_neg_samples=num_test,\n",
    "                method='sparse'\n",
    "            ).t().to(DEVICE)\n",
    "\n",
    "            test_all_edges = torch.cat([test_pos, test_neg], dim=0)\n",
    "            test_labels = torch.cat([\n",
    "                torch.ones(num_test, device=DEVICE),\n",
    "                torch.zeros(num_test, device=DEVICE)\n",
    "            ])\n",
    "            unique_nodes = torch.unique(test_all_edges)\n",
    "\n",
    "            encoder.eval()\n",
    "            predictor.eval()\n",
    "\n",
    "            subgraph_loader = NeighborLoader(\n",
    "                pyg_data,\n",
    "                input_nodes=unique_nodes,\n",
    "                num_neighbors=[10, 5],\n",
    "                batch_size=8192,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            embedding_bank = torch.zeros((pyg_data.num_nodes, EMBEDDING_DIM), device=DEVICE)\n",
    "\n",
    "            for batch in tqdm(subgraph_loader, desc=f\"Encoding {model_name}-{dataset_name}\", leave=False):\n",
    "                batch = batch.to(DEVICE)\n",
    "                out = encoder(batch.x.float(), batch.edge_index)\n",
    "                embedding_bank[batch.n_id] = out\n",
    "\n",
    "            preds = predictor(embedding_bank, test_all_edges).detach().cpu()\n",
    "            labels = test_labels.detach().cpu()\n",
    "\n",
    "            auc = roc_auc_score(labels.numpy(), preds.numpy())\n",
    "            acc = accuracy_score(labels.numpy(), preds.numpy() > 0.3)\n",
    "            f1 = f1_score(labels.numpy(), preds.numpy() > 0.3)\n",
    "\n",
    "        model_save_path = os.path.join(MODEL_DIR, model_name, dataset_name)\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(encoder.state_dict(), os.path.join(model_save_path, 'encoder.pt'))\n",
    "        torch.save(predictor.state_dict(), os.path.join(model_save_path, 'predictor.pt'))\n",
    "\n",
    "        result = {\n",
    "            'model': model_name,\n",
    "            'dataset': dataset_name,\n",
    "            'AUC': auc,\n",
    "            'Accuracy': acc,\n",
    "            'F1': f1\n",
    "        }\n",
    "        all_results.append(result)\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(all_results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
